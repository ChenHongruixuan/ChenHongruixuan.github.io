<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="robots" content="index, follow" />
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="keywords" content="CHEN Hongruixuan, Remote Sensing, Image Processing, Deep Learning">
<link rel="stylesheet" href="./Files/jemdoc.css" type="text/css" />
<script src="jquery.min.js"></script>
<link rel="shortcut icon" href="./Files/icon.jpg">
<title>Hongruixuan's Homepage</title>
</head>
 
 
<body>

<a id="home" class="anchor"></a>
<div id="container"> 
<div class="container"> 

<table class="imgtable"><tr><td>
<a href="./"><img src="./Files/CHRX_2021.jpg" alt="" height="218px" /></a>&nbsp;</td>
<!-- <td align="left"><p><font size="4">CHEN Hongruixuan (</font><font size="4"; font style="font-family:Microsoft YaHei">陈洪瑞轩</font><font size="4">)</font><br /> -->
<td align="left"><p><font size="4">CHEN Hongruixuan</font><br />
<br />
<a href="http://www.ms.k.u-tokyo.ac.jp/" target="_blank">Sugiyama-Yokoya-Ishida Lab</a><br />
<a href="https://www.k.u-tokyo.ac.jp/en/" target="_blank">Graduate School of Frontier Sciences</a><br />
<a href="https://www.u-tokyo.ac.jp/en/" target="_blank">The University of Tokyo</a><br />
<br />
  
Email: Qschrx@gmail.com (prior); &nbsp;&nbsp; Qschrx@g.ecc.u-tokyo.ac.jp <br />
 
[<a href="https://scholar.google.com/citations?user=XOk4Cf0AAAAJ&hl=en" target="_blank">Google Scholar</a>] 
[<a href="https://github.com/ChenHongruixuan" target="_blank">GitHub</a>] 
[<a href="https://www.researchgate.net/profile/Hongruixuan-Chen" target="_blank">ResearchGate</a>] 
[<a href="https://orcid.org/0000-0003-0100-4786" target="_blank">ORCID</a>] 
[<a href="https://www.linkedin.com/in/hongruixuan-chen-993b06130/" target="_blank">Linkedin</a>] 
[<a href="./Files/CHEN Hongruixuan_CV.pdf" target="_blank">CV</a>]
<br />

<br />
Location: 5-1-5 Kashiwanoha, Kashiwa-shi, Chiba 277-8561, Japan<br />
 
<class="staffshortcut">
<A HREF="#Short Bio">Short Bio</A> | 
<A HREF="#News">News</A> | 
<A HREF="#Experience">Experience</A> | 
<A HREF="#Publications">Publications</A> | 
<A HREF="#Fundings">Fundings</A> | 
<!-- <A HREF="#Projects">Teaching</A> |  -->
<A HREF="#Services">Services</A> | 
<A HREF="#Resources">Resources</A> | 
<A HREF="#Awards">Awards</A>
<br />
 
</td></tr></table>

 
<A NAME="Short Bio"><h2>Short Bio</h2></A>
<p style="line-height:130%">CHEN Hongruixuan is currently a Ph.D student at <a href="http://www.ms.k.u-tokyo.ac.jp/" target="_blank">Machine Learning and Statistical Data Analysis Lab</a>, The University of Tokyo, advised by <a href="https://naotoyokoya.com/" target="_blank">Prof. Naoto Yokoya</a>. He was also an academic visitor of <a href="https://prs.igp.ethz.ch/" target="_blank">Photogrammetry and Remote Sensing Group</a>, <a href="https://ethz.ch/en.html" target="_blank">ETH Zurich</a> and an intern of The United Nations Satellite Center (UNOSAT). His current research is motivated by how to better monitor, describe and understand changes in our planet's surface by studying machine learning and computer vision approaches, thereby contributing to urban planning, resource management, environmental protection, and sustainable development. </p>
<!-- <ul>
<li><b>Multitemporal Remote Sensing Image Processing and Analysis</b>: Change Detection, Damage Assessment, Vehicle Counting</li>
<li><b>Unsupervised Domain Adaptation</b>: Semantic Segmentation</li>
<li><b>Machine Learning</b>: Deep Learning, Unsupervised Learning, Weakly Supervised Learning, Domain Adaptation</li>
</ul> --> 
<br />
<A NAME="News"><h2>News</h2></A>
<ul>
<li> <b> <font color="#FF0000">[2025.01]</font> </b> BRIGHT serves the official dataset of <b>IEEE GRSS Data Fusion Contest 2025</b> (<a href="https://github.com/ChenHongruixuan/BRIGHT" target="_blank">link</a>)!</li>    
<li> <b> <font color="#FF0000">[2024.11]</font> </b> ChangeMamba has been selected as <b>ESI Hot Paper</b>!</li>    
<li> <b> <font color="#FF0000">[2024.11]</font> </b> Our co-authored paper has been accepted by <b>IEEE GRSL</b> (<a href="https://ieeexplore.ieee.org/document/10741284/" target="_blank">link</a>)!</li>    
<li> <b> <font color="#FF0000">[2024.10]</font> </b> One co-authored paper has been accepted by <b>NeurIPS 2024 Spotlight</b> (<a href="https://jtrneo.github.io/SynRS3D/" target="_blank">link</a>)!</li>
<li> <b> <font color="#FF0000">[2024.09]</font> </b> Acted as Guest Editor Assistant of Remote Sensing (<a href="https://www.mdpi.com/journal/remotesensing/special_issues/X56I1Z0D89" target="_blank">link</a>)!</li>
<li> <b> <font color="#FF0000">[2024.09]</font> </b> ChangeMamba has been selected as <b>ESI Highly Cited Paper</b>!</li> 
<li> <b> <font color="#FF0000">[2024.07]</font> </b> Three papers have been selected as <b>ESI Highly Cited Paper</b>!</li> 
<li> <b> <font color="#FF0000">[2024.07]</font> </b> ChangeMamba has been selected as <b>IEEE GRSS Weekly Paper</b> (<a href="https://www.linkedin.com/feed/update/urn:li:activity:7219970529498214400/" target="_blank">link</a>)!</li> 
<li> <b> <font color="#FF0000">[2024.06]</font> </b> One paper has been accepted by <b>IEEE TGRS</b> (<a href="https://ieeexplore.ieee.org/document/10565926" target="_blank">link</a>)!</li> 
<li> <b> <font color="#FF0000">[2024.06]</font> </b> One co-authored paper has been accepted by <b>IEEE GRSM</b> (<a href="https://ieeexplore.ieee.org/document/10616141" target="_blank">link</a>)!</li> 
<li> <b> <font color="#FF0000">[2024.05]</font> </b> One paper has been accepted by <b>IEEE TGRS</b> (<a href="https://ieeexplore.ieee.org/document/10551264" target="_blank">link</a>)!</li>
<li> <b> <font color="#FF0000">[2024.03]</font> </b> One <a href="https://www.sciencedirect.com/science/article/pii/S092427162300062X" target="_blank">paper</a> has been awarded as ESI highly cited paper (<a href="https://www.webofscience.com/wos/woscc/full-record/WOS:000956736300001" target="_blank">link</a>)!</li>
<li> <b> <font color="#FF0000">[2024.02]</font> </b> One co-authored paper has been accepted by <b>IEEE TGRS</b> (<a href="https://ieeexplore.ieee.org/document/10445496" target="_blank">link</a>)!</li>
<li> <b> <font color="#FF0000">[2023.12]</font> </b> Received AI Center Fusion Research Promotion Fund!</li>
</ul>
<br />

 
<A NAME="Experience"><h2>Experience</h2></A>
<p><b>Work/Overseas Experience</b>: </p>
<font size="3"> 
<ul>
<li>2024.01-2024.07 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Academic Visitor, <a href="https://prs.igp.ethz.ch/" target="_blank">Photogrammetry and Remote Sensing Group</a>, <a href="https://ethz.ch/en.html" target="_blank">ETH Zurich</a>. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Host: Prof. <a href="https://scholar.google.com/citations?user=FZuNgqIAAAAJ&hl=en" target="_blank">Konrad Schindler</a></li>
<li>2023.05-2024.01 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Research Part-time Worker, <a href="https://www.riken.jp/en/research/labs/aip/goalorient_tech/geoinf/index.html" target="_blank">Geoinformatics Team</a>, <a href="https://www.riken.jp/en/research/labs/aip/" target="_blank">RIKEN AIP</a>. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Host: Prof. <a href="https://scholar.google.com/citations?user=FZuNgqIAAAAJ&hl=en" target="_blank">Naoto Yokoya</a></li></li>
<li>2022.11-2023.03 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Research Assistant, <a href="https://beyondai.jp/?lang=en" target="_blank">Beyond AI</a>, <a href="https://www.u-tokyo.ac.jp/en/" target="_blank">The University of Tokyo</a></li>
<li>2021.05-2022.05 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Trainee, <a href="https://unosat.org/" target="_blank">The United Nations Satellite Centre</a>, <a href="https://unitar.org/" target="_blank">The United Nations Institute for Training and Research</a></li>
</font>
</ul>
<br />
 
<p><b>Education Experience</b>: </p>
<font size="3"> 
<ul>
<li>2022.10-2025.09 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Ph.D. in <a href="https://www.k.u-tokyo.ac.jp/en/" target="_blank">Graduate School of Frontier Sciences</a>, <a href="https://www.u-tokyo.ac.jp/en/" target="_blank">The University of Tokyo</a>. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Supervisor: Prof. <a href="https://naotoyokoya.com/" target="_blank">Naoto Yokoya</a></li>
<li>2019.09-2022.06 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; M.E. in <a href="http://www.lmars.whu.edu.cn/" target="_blank">State Key Laboratory of Information Engineering in Surveying, Mapping and Remote Sensing</a>, <a href="https://www.whu.edu.cn/" target="_blank">Wuhan University</a>. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Supervisor: Prof. <a href="https://scholar.google.com/citations?user=DbTt_CcAAAAJ&hl=zh-CN" target="_blank">Chen Wu</a>, Prof. <a href="https://scholar.google.com/citations?hl=zh-CN&user=Shy1gnMAAAAJ" target="_blank">Bo Du</a>, Prof. <a href="https://scholar.google.com/citations?user=vzj2hcYAAAAJ&hl=zh-CN" target="_blank">Liangpei Zhang</a></li>
<li>2015.09-2019.06 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; B.E. in <a href="https://en.ahu.edu.cn/enzyyhj/" target="_blank">School of Resources and Environmental Engineering</a>, <a href="https://en.ahu.edu.cn/" target="_blank">Anhui University</a>. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Supervisor: Prof. Yanlan Wu and Prof. Peng Jiang</a></li>
</ul>
</font>
<br />

 
<A NAME="Publications"><h2>Selected Publications</h2></A>
<p><b>Multimodal Change Detection</b>: </p>
<table width="100%" class="imgtable">
    <tr>
       <td width="306"> <img src="Files/bright_overall_linked.jpg" width="290px"> </td>
       <td>
           <a href="https://arxiv.org/abs/2501.06019">BRIGHT: A Globally Distributed Multimodal Building Damage Assessment Dataset with Very-high-resolution for All-weather Disaster Response</a>
               <br><b>H. Chen</b>,J. Song, O. Dietrich, C. Broni-Bediako, W. Xuan, J. Wang, X. Shao, Y. Wei, J. Xia, C. Lan, K. Schindler and N. Yokoya
           <br>[<a href="https://arxiv.org/abs/2501.06019">Paper</a>][<a href="https://github.com/ChenHongruixuan/BRIGHT">Code</a>][<a href="https://github.com/ChenHongruixuan/BRIGHT">Data</a>][<a href="https://www.grss-ieee.org/technical-committees/image-analysis-and-data-fusion/?tab=data-fusion-contest">Contest</a>]
       </td>
   </tr>
   </table>

<table width="100%" class="imgtable">
    <tr>
       <td width="306"> <img src="Files/ObjFormer.jpg" width="290px"> </td>
       <td>
           <a href="https://ieeexplore.ieee.org/document/10551264">ObjFormer: Learning Land-Cover Changes From Paired OpenStreetMap Data and Optical High-Resolution Imagery via Object-Guided Transformer</a>
               <br><b>H. Chen</b>, C. Lan, J. Song, C Broni-Bedaiko, J. Xia, and N. Yokoya
               <br><i>IEEE Transactions on Geoscience and Remote Sensing (<b><i>TGRS</i></b>)</i>, 2024. 
           <br>[<a href="https://ieeexplore.ieee.org/document/10551264">Paper</a>][<a href="https://github.com/ChenHongruixuan/ObjFormer">Code</a>][<a href="https://github.com/ChenHongruixuan/ObjFormer">Data</a>]
       </td>
   </tr>
   </table>
<table width="100%" class="imgtable">
    <tr>
        <td width="306"> <img src="Files/FDMCD.jpg" width="290px"></td>
        <td>
            <a href="https://www.sciencedirect.com/science/article/pii/S092427162300062X">Fourier Domain Structural Relationship Analysis for Unsuperivsed Multimodal Change Detection</a>
            <br><b>H. Chen</b>, N. Yokoya, and M. Chini
            <br><i>ISPRS Journal of Photogrammetry and Remote Sensing</i>, 2023. (<b><font color="#FF0000">ESI Highly Cited Paper</font></b>) 
            <br>[<a href="https://www.sciencedirect.com/science/article/pii/S092427162300062X">Paper</a>][<a href="https://github.com/ChenHongruixuan/FDMCD">Code</a>]
        </td>
    </tr>
    </table>
<table width="100%" class="imgtable">
    <tr>
        <td width="306"> <img src="Files/SRGCAE.jpg" width="290px"></td>
        <td>
            <a href="https://ieeexplore.ieee.org/document/9984688">Unsupervised Multimodal Change Detection Based on Structural Relationship Graph Representation Learning</a>
            <br><b>H. Chen</b>, N. Yokoya, C. Wu, and B. Du
            <br><i>IEEE Transactions on Geoscience and Remote Sensing (<b><i>TGRS</i></b>)</i>, 2022. 
            <br>[<a href="https://ieeexplore.ieee.org/document/9984688">Paper</a>][<a href="https://github.com/ChenHongruixuan/SRGCAE">Code</a>][<a href="https://github.com/ChenHongruixuan/SRGCAE">Data</a>]
        </td>
    </tr>
    </table>
<table width="100%" class="imgtable">
    <tr>
        <td width="306"> <img src="Files/SiamCRNN.png" width="290px"></td>
        <td>
            <a href="https://ieeexplore.ieee.org/document/8937755">Change Detection in Multisource VHR Images via Deep Siamese Convolutional Multiple-Layers Recurrent Neural Network</a>
            <br><b>H. Chen</b>, C. Wu, B. Du, L. Zhang, and L. Wang
            <br><i>IEEE Transactions on Geoscience and Remote Sensing (<b><i>TGRS</i></b>)</i>, 2020. (<b><font color="#FF0000">ESI Highly Cited Paper</font></b>) 
            <br>[<a href="https://ieeexplore.ieee.org/document/8937755">Paper</a>][<a href="https://github.com/ChenHongruixuan/SiamCRNN">Code</a>][<a href="https://github.com/ChenHongruixuan/SiamCRNN">Data</a>]
        </td>
    </tr>
</table>
<br />
<br />
<p><b>Unimodal Change Detection</b>: </p>
<table width="100%" class="imgtable">
    <tr>
       <td width="306"> <img src="Files/ChangeMamba.jpg" width="290px"> </td>
       <td>
           <a href="https://ieeexplore.ieee.org/document/10565926">ChangeMamba: Remote Sensing Change Detection with Spatio-Temporal State Space Model</a>
               <br><b>H. Chen</b>, J. Song, C. Han, J. Xia, and N. Yokoya
               <br><i>IEEE Transactions on Geoscience and Remote Sensing (<b><i>TGRS</i></b>)</i>, 2024. (<b><font color="#FF0000">ESI Hot Paper / ESI Highly Cited Paper</font></b>) 
           <br>[<a href="https://ieeexplore.ieee.org/document/10565926">Paper</a>][<a href="https://github.com/ChenHongruixuan/MambaCD">Code</a>][<a href="https://www.linkedin.com/feed/update/urn:li:activity:7219970529498214400/">News</a>]
       </td>
   </tr>
   </table>
<table width="100%" class="imgtable">
    <tr>
       <td width="306"> <img src="Files/I3PE.jpg" width="290px"> </td>
       <td>
           <a href="https://www.sciencedirect.com/science/article/pii/S092427162300309X">Exchange Means Change: An Unsupervised Single-Temporal Change Detection Framework Based on Intra- and Inter-Image Patch Exchange</a>
               <br><b>H. Chen</b>, J. Song, C. Wu, B. Du, and N. Yokoya
           <br><i>ISPRS Journal of Photogrammetry and Remote Sensing</i>, 2023.
           <br>[<a href="https://www.sciencedirect.com/science/article/pii/S092427162300309X">Paper</a>][<a href="https://github.com/ChenHongruixuan/I3PE">Code</a>][<a href="https://github.com/ChenHongruixuan/I3PE">Data</a>]
       </td>
   </tr>
   </table>
<table width="100%" class="imgtable">
     <tr>
        <td width="306"> <img src="Files/KPCAMNet.png" width="290px"> </td>
        <td>
            <a href="https://ieeexplore.ieee.org/abstract/document/9477493">Unsupervised Change Detection in Multitemporal VHR Images Based on Deep Kernel PCA Convolutional Mapping Network</a>
                <br>C. Wu, <b>H. Chen</b>, B. Du, and L. Zhang
            <br><i>IEEE Transactions on Cybernetics (<b><i>TCYB</i></b>)</i>, 2021.
            <br>[<a href="https://ieeexplore.ieee.org/abstract/document/9477493">Paper</a>][<a href="https://github.com/ChenHongruixuan/KPCAMNet">Code</a>][<a href="https://github.com/ChenHongruixuan/KPCAMNet">Data</a>]
        </td>
    </tr>
    </table>
<br />
<br />
<p><b>Multitemporal Image Analysis and Application</b>: </p>

<table width="100%" class="imgtable">
    <tr>
        <td width="306"> <img src="Files/SyntheWorld.jpg" width="290px"></td>
        <td>
            <a href="https://arxiv.org/abs/2309.01907">SyntheWorld: A Large-Scale Synthetic Dataset for Land Cover Mapping and Building Change Detection</a>
            <br>J. Song, <b>H. Chen</b>, and N. Yokoya
            <br><i>IEEE/CVF Winter Conference on Applications of Computer Vision (<b><i>WACV</i></b>)</i>, 2024.
            <br>[<a href="https://arxiv.org/abs/2309.01907">Paper</a>][<a href="https://github.com/JTRNEO/SyntheWorld">Data</a>]
        </td>
    </tr>
</table>
<table width="100%" class="imgtable">
    <tr>
        <td width="306"> <img src="Files/DamFormer.jpg" width="290px"></td>
        <td>
            <a href="https://ieeexplore.ieee.org/document/9883139/">Dual-Tasks Siamese Transformer Framework for Building Damage Assessment</a>
            <br><b>H. Chen</b>, E. Nemni, S. Vallecorsa, X. Li, C. Wu, and L. Bromley
            <br><i>Proceeding of the IEEE International Geoscience and Remote Sensing Symposium (<b><i>IGARSS</i></b>)</i>, 2022.
            <br>[<a href="https://ieeexplore.ieee.org/document/9883139/">Paper</a>][<a href="https://xview2.org/">Data</a>][<a href="https://unitar.org/about/news-stories/news/celebrating-2-years-collaboration-wuhan-university-ai-research-remote-sensing">News</a>]
        </td>
    </tr>
</table>
<table width="100%" class="imgtable">
    <tr>
        <td width="306"> <img src="Files/COVID_WHU.jpg" width="290px"> </td>
        <td>
            <a href="https://www.sciencedirect.com/science/article/pii/S0303243421002105">An Investigation of Traffic Density Changes inside Wuhan during the COVID-19 Epidemic with GF-2 Time-Series Images</a>
                <br>C. Wu, Y. Guo, H. Guo, J. Yuan, L. Ru, <b>H. Chen</b>, B. Du, and L. Zhang
            <br><i>International Journal of Applied Earth Observation and Geoinformation (<b><i>JAG</i></b>)</i>, 2021.
            <br>[<a href="https://www.sciencedirect.com/science/article/pii/S0303243421002105">Paper</a>]
        </td>
    </tr>
</table>
<br />

 

<A NAME="Fundings"><h2>Fundings</h2></A>
<font size="3"> 
<ul>
<li>2024.10 - 2025.09, PI, AI Center Fusion Research Promotion Fund (ＡＩセンター融合研究促進費)</li>
<li>2024.04 - 2025.09, PI, Grant-in-Aid for JSPS Research Fellows (特別研究員奨励費)</li>
<li>2023.12 - 2024.12, PI, AI Center Fusion Research Promotion Fund (ＡＩセンター融合研究促進費)</li>
<li>2024.01 - 2024.07, PI, Young Researchers' Exchange Programme Special 2023 Exchange Grant Japan</li>
<li>2023.06 - 2024.03, PI, GSFS Challenging New Area Doctoral Research Grant (GSFS Challenge Fund)</li>
<li>2023.04 - 2024.03, PI, Microsoft Research Asia Collaborative Research Program Fellowship (MSRA D-CORE 2023)</li>
<li>2016.11 - 2018.11, PI, Chinese National Innovative Research Project for Undergraduate Students</li>
</ul>
</font>
<br />


 
<A NAME="Services"><h2>Services</h2></A>

<!-- <p><b>Conference Organization</b>: </p>
<font size="3"> 
<ul>
<li>IGARSS 2021, <b>Session Chair</b> (Session: <a href= "https://igarss2021.com/view_session.php?SessionID=1105" target="_blank">Image Restoration</a>)</li>
</ul>
</font>
<br />
<br />
<br /> -->
 
<p><b>Membership</b>: </p>
<font size="3"> 
<ul>
<li>IEEE, Student Member</li>
<li>IEEE Geoscience and Remote Sensing Society (GRSS), Student Member</li>

</ul>
</font>
<br />
 
<p><b>Journal Reviewer</b>: </p>
<font size="3"> 
<ul>
<li>IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>)</li>
<li>IEEE Transactions on Image Processing (<b>TIP</b>)</li>
<li>IEEE Transactions on Neural Networks and Learning Systems (<b>TNNLS</b>)</li>
<li>IEEE Transactions on Geoscience and Remote Sensing (<b>TGRS</b>)</li>
<li>IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing (<b>JSTARS</b>)</li>
<li>IEEE Geoscience and Remote Sensing Letters (<b>LGRS</b>)</li>
<li>ISPRS Journal of Photogrammetry and Remote Sensing (<b>P & RS</b>)</li>
<li>Pattern Recognition (<b>PR</b>)</li>
<li>International Journal of Applied Earth Observation and Geoinformation (<b>JAG</b>)</li>
<li>Artificial Intelligence Review</li>
<li>Geo-Spatial Information Science (<b>GSIS</b>)</li>
<li>Neurocomputing</li>
<li>International Journal of Digital Earth</li>
<li>....</li>
</ul>
</font>
<br />

<p><b>Conference Reviewer</b>: </p>
<font size="3"> 
<ul>
<li>IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (<b>CVPRW</b>)</li>
</ul>
</font>
<br />
 
<A NAME="Resources"><h2>Resources</h2></A>

<p><b>Codes</b>: </p>
<font size="3"> 
<ul>
<li>Change Detection Repo (<a href= "https://github.com/ChenHongruixuan/ChangeDetectionRepository" target="_blank">Code</a>)</li>
<li>ChangeMamba (<a href= "https://github.com/ChenHongruixuan/MambaCD" target="_blank">Code</a>)</li>
<li>ObjFormer (<a href= "https://github.com/ChenHongruixuan/ObjFormer" target="_blank">Code</a>)</li>
<li>I3PE (<a href= "https://github.com/ChenHongruixuan/I3PE" target="_blank">Code</a>)</li>
<li>FDMCD (<a href= "https://github.com/ChenHongruixuan/FDMCD" target="_blank">Code</a>)</li>
<li>SR-GCAE (<a href= "https://github.com/ChenHongruixuan/SRGCAE" target="_blank">Code</a>)</li>
<li>SiamCRNN (<a href= "https://github.com/ChenHongruixuan/SiamCRNN" target="_blank">Code</a>)</li>
<li>KPCA-MNet (<a href= "https://github.com/ChenHongruixuan/KPCAMNet" target="_blank">Code</a>)</li>
<li>DSMSCN (<a href= "https://github.com/ChenHongruixuan/DSMSCN" target="_blank">Code</a>)</li>
</ul>
</font>
<br />
 
<p><b>Datasets</b>: </p>
<font size="3"> 
<ul>
<li>BRIGHT dataset (<a href= "https://github.com/ChenHongruixuan/BRIGHT" target="_blank">Dataset</a>)</li>
<li>OpenMapCD dataset (<a href= "https://github.com/ChenHongruixuan/ObjFormer" target="_blank">Dataset</a>)</li>
<li>SynRS3D dataset (<a href= "https://github.com/JTRNEO/SynRS3D" target="_blank">Dataset</a>)</li>
<li>CoralReef dataset (<a href= "https://github.com/xl-shao/coralconditiondataset" target="_blank">Dataset</a>)</li>
<li>Wuhan dataset (<a href= "https://github.com/ChenHongruixuan/I3PE" target="_blank">Dataset</a>)</li>
<li>SyntheWorld dataset (<a href= "https://github.com/JTRNEO/SyntheWorld" target="_blank">Dataset</a>)</li>
<li>GF-2 change detection dataset (<a href= "http://sigma.whu.edu.cn/resource.php" target="_blank">Dataset</a>)</li>
<li>Wuhan Multi-Application VHR Scene classification dataset (WH-MAVS) (<a href= "http://sigma.whu.edu.cn/newspage.php?q=2021_06_27" target="_blank">Dataset</a>)</li>
</ul>
</font>
<br />


<A NAME="Awards"><h2>Awards</h2></A>
<font size="3"> 
<ul>
<li>2023, Japan Society for the Promotion of Science (JSPS, 日本学術振興会) DC2 Research Fellowship</li>    
<li>2023, Young Researchers' Exchange Programme Special 2023 Exchange Grant</li>    
<li>2023, GSFS Challenging New Area Doctoral Research Grant (GSFS Challenge Fund)</li>
<li>2023, MSRA Collaborative Research Program Fellowship (D-CORE 2023)</li>
<li>2022, The University of Tokyo Fellowship (Todai Fellowship) | <font style="font-family:Microsoft YaHei">东京大学奖学金</font></li>
<li>2022, Outstanding Graduate Student, Wuhan University | <font style="font-family:Microsoft YaHei">武汉大学优秀毕业研究生</font></li>
<li>2021, Wang Zhizhuo Innovation Talent Scholarship, Wuhan University | <font style="font-family:Microsoft YaHei">王之卓创新人才奖学金</font></li>
<li>2021, National Scholarship for Postgraduates, Ministry of Education | <font style="font-family:Microsoft YaHei">硕士研究生国家奖学金</font></li>
<li>2021, First Prize of Academic Scholarship, Wuhan University | <font style="font-family:Microsoft YaHei">武汉大学学业奖学金一等奖</font></li>
<li>2021, Outstanding Graduate Student, Wuhan University | <font style="font-family:Microsoft YaHei">武汉大学优秀研究生</font></li>
<li>2020, National Scholarship for Postgraduates, Ministry of Education | <font style="font-family:Microsoft YaHei">硕士研究生国家奖学金</font></li>
<li>2020, First Prize of Academic Scholarship, Wuhan University | <font style="font-family:Microsoft YaHei">武汉大学学业奖学金一等奖</font></li>
<li>2020, Outstanding Graduate Student, Wuhan University | <font style="font-family:Microsoft YaHei">武汉大学优秀研究生</font></li>
<li>2019, LIESMARS Scholarship for Excellent First-Year Postgraduates, LIESMARS | <font style="font-family:Microsoft YaHei">LIESMARS优秀硕士新生奖学金</font></li>
<li>2019, Excellent Graduate of Anhui Province, Anhui Province Department of Education | <font style="font-family:Microsoft YaHei">安徽省品学兼优毕业生</font></li>
<li>2018, First Prizes of Academic Scholarship of Anhui University, Anhui University | <font style="font-family:Microsoft YaHei">安徽大学一等学术奖学金</font></li>
<li>2018, Second Prize of Esri Cup GIS Software Development Contest in China, Chinese Society for Geodesy | <font style="font-family:Microsoft YaHei">Esri杯GIS软件开发大赛二等奖</font></li>
<li>2018, Outstanding Prize of National Geomatics Contest in Programming, The State Bureau of Surveying and Mapping | <font style="font-family:Microsoft YaHei">全国大学生测绘技能大赛编程特等奖</font></li>
<li>2018, Meritorious Winner of the US Mathematical Contest in Modeling, Consortium For Mathematics & Its Applications | <font style="font-family:Microsoft YaHei">美国大学生数学建模竞赛一等奖</font></li>
<li>2017, Second Prize of China National Mathematical Contest in Modeling, Society for Industrial and Applied Mathematics | <font style="font-family:Microsoft YaHei">全国大学生数学建模竞赛二等奖</font></li>
<li>2017, National Scholarship for Undergraduates, Ministry of Education | <font style="font-family:Microsoft YaHei">本科生国家奖学金</font></li>
<li>2016, Anhui University Scholarship for Excellent Students, Anhui University | <font style="font-family:Microsoft YaHei">安徽大学优秀学生奖学金</font></li>
</ul>
</font>
 
<br />
<br />


<script type="text/javascript" src="//rf.revolvermaps.com/0/0/6.js?i=5wnt4xcuiev&amp;m=6&amp;c=ff0000&amp;cr1=ffffff&amp;f=arial&amp;l=1" async="async"></script>

<div id="article"></div>
<div id="back_top">
<div class="arrow"></div>
<div class="stick"></div>
</div>

<script>
$(function(){
    $(window).scroll(function(){  //If scroll
        var scrollt = document.documentElement.scrollTop + document.body.scrollTop; //Getting Height after scroll
        if( scrollt >400 )
        {  
            $("#back_top").fadeIn(400); 
        }
        else
        {
            $("#back_top").stop().fadeOut(400);
        }
    });

    $("#back_top").click(function(){ 

        $("html,body").animate({scrollTop:"0px"}, 200);

    }); 

});
</script>


<!--
All Rights Reserved by Qiang Zhang. Part of page is generated by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
-->

<!--
<font size="2"; color="#A0A0A0";>
<p style="text-align:center">Updating time: 2022.07.07</p>
</font>
-->

</body>
</html>
